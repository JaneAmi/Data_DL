{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4WWyW4tM2Ir"
      },
      "source": [
        "# Deep Learning Theoretical Aspects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u1ZXXN9lM2Is"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1KZDDKnehj"
      },
      "source": [
        "### Q1: Nonlinerity (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2qwj-IZM2Iw"
      },
      "source": [
        "Much of the power of neural networks comes from the nonlinearity that is inherited in activation functions.  \n",
        "Show that a network of N layers that uses a linear activation function can be reduced into a network with just an input and output layers.\n",
        "\n",
        "(Write down what is the output of two layers and use induction to claim for all layers).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<u>Answer</u>\n",
        "\n",
        "Let's assume we have $x_1$ in input and it goes through next layers:\n",
        "\n",
        "1. Layer 1 with a linear activation function:\n",
        "$z_1(x_1) = w_1 * x_1 + b_1$\n",
        "\n",
        "2. Than it goes through layer 2 with a linear activation function:\n",
        "$z_2(z_1(x_1)) = w_2 * z_1(x_1) + b_2$\n",
        "\n",
        "Now let's calculate the output y:\n",
        "\n",
        "$y = w_2 * (w_1 * x_1 + b_1) + b_2$\n",
        "\n",
        "If we will open this equation we will get another linear function:\n",
        "$y = (w_1 * w_2)x_1 + (w_2 * b_1 + b_2)$\n",
        "\n",
        "Let $W = w_1 * w_2$ and $B = w_2 * b_1 + b_2$, therefore the equation will look like: $y=W*x_i + B$\n",
        "\n",
        "Hence no matter how many layers there are with linear activation function they can be represented as a single layer with a linear function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e-VlB4eM2Iz"
      },
      "source": [
        "### Q2: Derivatives of Activation Functions (15 points)\n",
        "Compute the derivative of these activation functions:\n",
        "\n",
        "1 Sigmoid\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*Vo7UFksa_8Ne5HcfEzHNWQ.png\" width=\"150\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk-7BzFQM2I0"
      },
      "source": [
        "The derivative is:\n",
        "$f'(t) = \\frac{e^{-t}}{(1+e^{-t})^2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0AiF6YjM2I3"
      },
      "source": [
        "2 Relu\n",
        "\n",
        "<img src=\"https://cloud.githubusercontent.com/assets/14886380/22743194/73ca0834-ee54-11e6-903f-a7efd247406b.png\" width=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWTRtEX8M2I4"
      },
      "source": [
        "The derivative is:\n",
        "\n",
        "$f'(x) = \\begin{cases} 1& \\text{if} & x > 0, \\\\ 0\\end{cases}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tcbCKStM2I7"
      },
      "source": [
        "3 Softmax\n",
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3\" width=\"250\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qb8zeNBM2I8"
      },
      "source": [
        "The derivative is:\n",
        "$\\sigma'(z)_j = \\frac{e^{z_j}}{\\sum_{k=1}^{K}e^{z_k}}\\bigg(1-\\frac{e^{z_j}}{\\sum_{k=1}^{K}e^{z_k}}\\bigg)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRE-pv-zM2I-"
      },
      "source": [
        "### Q3: Back Propagation (30 points)\n",
        "Use the chain rule and backprop (also called the generalized delta rule) to compute the partial derivatives for these computations (i.e., dz/dx1, dz/dx1, dz/dx3):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sJZ_0mWM2JA"
      },
      "source": [
        "```\n",
        "z = x1 + 5*x2 - 3*x3^2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Answer:\n",
        "\n",
        "$\\frac{dz}{dx_1} = 1$\n",
        "\n",
        "$\\frac{dz}{dx_2} = 5$\n",
        "\n",
        "$\\frac{dz}{dx_3} = -6x_3$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgwnBRJgM2JD"
      },
      "source": [
        "```\n",
        "z = x1*(x2-4) + exp(x3^2) / 5*x4^2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Answer:\n",
        "\n",
        "$\\frac{dz}{dx_1} = x_2-4$\n",
        "\n",
        "$\\frac{dz}{dx_2} = x_1$\n",
        "\n",
        "$\\frac{dz}{dx_3} = \\frac{2x_3e^{x_3^2}}{5x_4^2}$\n",
        "\n",
        "$\\frac{dz}{dx_4} = -\\frac{2e^{x_3^2}}{5x_4^3}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCIx61WAM2JI"
      },
      "source": [
        "```\n",
        "z = 1/x3 + exp( (x1+5*(x2+3)) ^2 )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSdvzQTlM2JJ"
      },
      "source": [
        "Answer:\n",
        "\n",
        "$\\frac{dz}{dx_1} = (2x_1 + 10x_2 + 30)e^{(x_1+5(x_2+3))^2}$\n",
        "\n",
        "$\\frac{dz}{dx_1} = (10x_1 + 50x_2 + 150)e^{(x_1+5(x_2+3))^2}$\n",
        "\n",
        "$\\frac{dz}{dx_3} = -\\frac{1}{x_3^2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvTBLm44M2Jq"
      },
      "source": [
        "### Q4: Puppy or bagel? (20 points)\n",
        "We've seen in class the funny examples of challenging images (Chihuahua or muffin, puppy or bagel etc.).\n",
        "\n",
        "Let's say you were asked by someone to find more examples like that. You are able to call the 3 neural networks that won the recent ImageNet challenges, and get their predictions (the entire vector of probabilities for the 1000 classes).  \n",
        "\n",
        "Describe methods that might assist you in finding more examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<u>Answer:</u>\n",
        "\n",
        "<b>1. High Entropy in Predictions</b>: High entropy values suggest that the network is unsure, possibly because the image contains elements of different classes that are hard to distinguish. Calculate the entropy of the prediction vector for each image and find images where the neural network's prediction distribution has high entropy.\n",
        "\n",
        "<b>2. Close Probabilities for Target Categories</b>: Search for images where the probability difference between the two interesting classes (e.g., \"puppy\" and \"bagel\") is below a certain threshold, it shows that the network is almost equally likely to classify the image as either category.\n",
        "\n",
        "<b>3. Disagreement Among Models</b>: For each image, compare the top predictions of each model. If there's significant disagreement among the models regarding the top predicted class for an image, it may indicate an image that fits the \"puppy or bagel\" pattern.\n",
        "\n",
        "<b>4. Analyzing Misclassified Images</b>: For each model, sort images by the confidence level of incorrect predictions, these are images for which the model was confident about a wrong prediction. Specifically look at images that were strongly misclassified by any of the models and check if they belong to pairs of classes known to be visually similar. \n",
        "\n",
        "<b>5. Clustering of Prediction Vectors</b>: Perform clustering on the space of prediction vectors, snalyze the clusters to find those that contain a high diversity of classes. Images that are central to such clusters might be visually ambiguous.\n",
        "\n",
        "<b>6. Visual Similarity Analysis</b>: Use a feature extraction layer from one of the neural networks to get feature vectors for images. Compute similarity scores between images within ambiguous pairs of classes (like \"puppy\" vs. \"bagel\"). High similarity scores within such pairs may indicate images that are visually similar across different classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09DvXmg1oTtO"
      },
      "source": [
        "### Q5: Convolution (20 points)\n",
        "Consider the following convolution filters:\n",
        "```python\n",
        "k1 = [ [0 0 0], [0 1 0], [0 0 0] ]\n",
        "k2 = [ [0 0 0], [0 0 1], [0 0 0] ]\n",
        "k3 = [ [-1-1 -1], [-1 8 -1], [-1 -1 -1] ]\n",
        "k4 = [ [1 1 1], [1 1 1], [1 1 1] ] / 9\n",
        "```\n",
        "\n",
        "Can you guess what each of them computes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slhWF-YDoT8_"
      },
      "source": [
        "<u>Answer: </u>\n",
        "\n",
        "k1 - this filter yields the center pixel, that means it leaves the image unchanged\n",
        "\n",
        "k2 - this filter yields the right pixel to the center, that means that is shifts the picture one pixel to the left\n",
        "\n",
        "k3 - this filter makes stronger the current center pixel by 8 and substracts surrounding pixels with -1, it ephasizes edges\n",
        "\n",
        "k4 - this filter calculates the average pixels value, that means it blurrs the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
